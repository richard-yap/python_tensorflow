{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Edited1 3b-TF-FcNN-MNIST-Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn3HLUum9j2q",
        "colab_type": "text"
      },
      "source": [
        "### NN model for MNIST dataset\n",
        "- NN Model: 4 Hidden Layers (400, 200, 100, 50 neurons respectively)\n",
        "- Activation Function: Sigmoid\n",
        "- Learning Parameter: 0.001\n",
        "- #-of Training Epochs: 5\n",
        "- Batch Size: 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPQuvWWr9ph3",
        "colab_type": "code",
        "outputId": "e657c816-e18e-478c-de9a-9c220ffd4fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBATOpGJ9-Pn",
        "colab_type": "code",
        "outputId": "0c978dcf-ee08-4d37-a597-83a1423a3da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTYLcb9q-CxL",
        "colab_type": "code",
        "outputId": "114defe8-e0fd-4933-c0a6-8486de65d6f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sASl28Zh-Gt0",
        "colab_type": "code",
        "outputId": "7dc620d2-12b8-4b5c-ad6c-47e798ba25a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Business Model Canvas.gdoc'  'Leftovers .gdoc'\n",
            " \u001b[0m\u001b[01;34mCITREP_Data+Code\u001b[0m/            'Oral Presentation.gdoc'\n",
            " \u001b[01;34mClassroom\u001b[0m/                   'Quality Control.gdoc'\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/            'Quality Control Slides.gslides'\n",
            "'Getting started.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq9YgJ7K-I62",
        "colab_type": "code",
        "outputId": "daa3e766-89af-42e8-8b9b-f351e7d67368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd CITREP_Data+Code/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CITREP_Data+Code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3VDOX7y-KCl",
        "colab_type": "code",
        "outputId": "70f6aae1-d986-4b31-b057-4abb56404546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 2a-TensorFlow-Data-Loading.ipynb\n",
            " 2b-TensorFlow-ML.ipynb\n",
            " 3a-TF-FcNN-MNIST.ipynb\n",
            " 3b-TF-FcNN-MNIST-Exercise.ipynb\n",
            " 3c-FcNN-CIFAR10.ipynb\n",
            " 3d-FcNN-CIFAR10-Exercise.ipynb\n",
            " 3-diabetic-NeuralNet-Exercise-TF.ipynb\n",
            " 3e-keras-FCNN-MNIST.ipynb\n",
            " 3f-keras-FcNN-dogscats.ipynb\n",
            " 3g-keras-FcNN-bloodcell-Exercise.ipynb\n",
            " 3h-keras-FC-AutoEncoder.ipynb\n",
            " 4a-MNIST-CNN-TF.ipynb\n",
            " 4b-CIFAR10-CNN-TF-Exercise.ipynb\n",
            " 5a-keras-CNN-dogscats.ipynb\n",
            " 5b-keras-CNN-Bloodcell.ipynb\n",
            " 5c-keras-Con-AutoEncoder.ipynb\n",
            " 5d-keras-Vgg16-dogscats.ipynb\n",
            " 5e-Resnet50-keras-dogscats-Exercise.ipynb\n",
            " 6-Semeion-Classification-SimpleCNN-Exercise.ipynb\n",
            " 7-RNN-IMDB.ipynb\n",
            "'CITREP+ - Clarence & Dr Sudipta - Deep Learning with Tensorflow and Python - v2.pdf'\n",
            " \u001b[0m\u001b[01;34mData\u001b[0m/\n",
            " \u001b[01;34mmnist\u001b[0m/\n",
            " \u001b[01;34mmodels\u001b[0m/\n",
            " tensorboard.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72zQiB1H9j2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "learning_rate = 0.001\n",
        "training_epochs = 5\n",
        "\n",
        "#data boxes (boxes contain 100 random data points from the dataset) \n",
        "#based on how much ram your com has, you can increase the batch size\n",
        "batch_size = 1000\n",
        "\n",
        "tf.set_random_seed(25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4xBVeyu9j2u",
        "colab_type": "code",
        "outputId": "322e35e6-291c-43a4-d1df-c3ed35110cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Initial Setup\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"mnist\", one_hot=True)\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMUK4FVn9j2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Build your Model\n",
        "\n",
        "L1 = 400\n",
        "L2 = 200\n",
        "L3 = 100\n",
        "L4 = 50\n",
        "\n",
        "#in between the input layer and hidden layer 1\n",
        "W1 = tf.Variable(tf.truncated_normal([784, L1], stddev=0.1)) \n",
        "B1 = tf.Variable(tf.truncated_normal([L1],stddev=0.1)) \n",
        "\n",
        "#in between hidden layer 1 and hidden layer 2\n",
        "W2 = tf.Variable(tf.truncated_normal([L1, L2], stddev=0.1))\n",
        "B2 = tf.Variable(tf.truncated_normal([L2],stddev=0.1))\n",
        "\n",
        "#in between hidden layer 2 and hidden layer 3\n",
        "W3 = tf.Variable(tf.truncated_normal([L2, L3], stddev=0.1))\n",
        "B3 = tf.Variable(tf.truncated_normal([L3],stddev=0.1))\n",
        "\n",
        "W4 = tf.Variable(tf.truncated_normal([L3, L4], stddev=0.1))\n",
        "B4 = tf.Variable(tf.truncated_normal([L4],stddev=0.1))\n",
        "\n",
        "W5 = tf.Variable(tf.truncated_normal([L4, 10], stddev=0.1))\n",
        "B5 = tf.Variable(tf.truncated_normal([10],stddev=0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S8yUbCW9j2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Setup\n",
        "Y1 = tf.nn.sigmoid(tf.matmul(X, W1) + B1)\n",
        "\n",
        "# if you split the syntax version it will look like this below:\n",
        "# Y11 = tf.matmul(X, W1) + B5\n",
        "# Y1 = tf.nn.sigmoid(Y11)\n",
        "\n",
        "\n",
        "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)\n",
        "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3)\n",
        "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4)\n",
        "\n",
        "#why need to use softmax activation function for yhat (Y5)?\n",
        "Ylogits = tf.matmul(Y4, W5) + B5\n",
        "yhat = tf.nn.softmax(Ylogits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ11B41z9j21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss Functions\n",
        "loss = tf.reduce_mean(\n",
        "   tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=Ylogits))\n",
        "\n",
        "# Optimizer\n",
        "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1081Jjy9j24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "is_correct = tf.equal(tf.argmax(y,1),tf.argmax(yhat,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVA_lr-Z9j26",
        "colab_type": "code",
        "outputId": "3dd51279-ac5c-48f3-f99d-4b6c8eaf88ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training Model\n",
        "for epoch in range(training_epochs):\n",
        "    num_batches = int(mnist.train.num_examples/batch_size)\n",
        "    for i in range(num_batches):\n",
        "        batch_X, batch_y = mnist.train.next_batch(batch_size)\n",
        "        train_data = {X: batch_X, y: batch_y}\n",
        "        sess.run(train, feed_dict=train_data)\n",
        "\n",
        "        print(epoch*num_batches+i+1, \"Training accuracy =\", sess.run(accuracy, feed_dict=train_data),\n",
        "              \"Loss =\", sess.run(loss, feed_dict=train_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Training accuracy = 0.105 Loss = 2.3521788\n",
            "2 Training accuracy = 0.111 Loss = 2.3340697\n",
            "3 Training accuracy = 0.11 Loss = 2.3181632\n",
            "4 Training accuracy = 0.192 Loss = 2.3087015\n",
            "5 Training accuracy = 0.196 Loss = 2.2975943\n",
            "6 Training accuracy = 0.14 Loss = 2.2932339\n",
            "7 Training accuracy = 0.116 Loss = 2.2972012\n",
            "8 Training accuracy = 0.114 Loss = 2.2948847\n",
            "9 Training accuracy = 0.114 Loss = 2.295015\n",
            "10 Training accuracy = 0.162 Loss = 2.2927272\n",
            "11 Training accuracy = 0.108 Loss = 2.2981813\n",
            "12 Training accuracy = 0.107 Loss = 2.2934086\n",
            "13 Training accuracy = 0.168 Loss = 2.2898197\n",
            "14 Training accuracy = 0.128 Loss = 2.2968042\n",
            "15 Training accuracy = 0.086 Loss = 2.2958515\n",
            "16 Training accuracy = 0.12 Loss = 2.2867155\n",
            "17 Training accuracy = 0.112 Loss = 2.282643\n",
            "18 Training accuracy = 0.115 Loss = 2.2869976\n",
            "19 Training accuracy = 0.094 Loss = 2.2801685\n",
            "20 Training accuracy = 0.145 Loss = 2.276205\n",
            "21 Training accuracy = 0.203 Loss = 2.2735949\n",
            "22 Training accuracy = 0.201 Loss = 2.2670465\n",
            "23 Training accuracy = 0.26 Loss = 2.2602198\n",
            "24 Training accuracy = 0.253 Loss = 2.2567778\n",
            "25 Training accuracy = 0.215 Loss = 2.2543983\n",
            "26 Training accuracy = 0.212 Loss = 2.250031\n",
            "27 Training accuracy = 0.193 Loss = 2.2465086\n",
            "28 Training accuracy = 0.214 Loss = 2.2387764\n",
            "29 Training accuracy = 0.225 Loss = 2.229554\n",
            "30 Training accuracy = 0.21 Loss = 2.2261784\n",
            "31 Training accuracy = 0.226 Loss = 2.216358\n",
            "32 Training accuracy = 0.241 Loss = 2.2075887\n",
            "33 Training accuracy = 0.253 Loss = 2.2040796\n",
            "34 Training accuracy = 0.307 Loss = 2.1875527\n",
            "35 Training accuracy = 0.307 Loss = 2.175854\n",
            "36 Training accuracy = 0.317 Loss = 2.1731422\n",
            "37 Training accuracy = 0.332 Loss = 2.1604195\n",
            "38 Training accuracy = 0.331 Loss = 2.1511757\n",
            "39 Training accuracy = 0.356 Loss = 2.1414938\n",
            "40 Training accuracy = 0.377 Loss = 2.1244888\n",
            "41 Training accuracy = 0.403 Loss = 2.1027102\n",
            "42 Training accuracy = 0.381 Loss = 2.0966256\n",
            "43 Training accuracy = 0.384 Loss = 2.0844862\n",
            "44 Training accuracy = 0.387 Loss = 2.0636177\n",
            "45 Training accuracy = 0.341 Loss = 2.0732636\n",
            "46 Training accuracy = 0.391 Loss = 2.0300348\n",
            "47 Training accuracy = 0.385 Loss = 2.0191333\n",
            "48 Training accuracy = 0.37 Loss = 2.0174513\n",
            "49 Training accuracy = 0.366 Loss = 1.9937456\n",
            "50 Training accuracy = 0.397 Loss = 1.9687212\n",
            "51 Training accuracy = 0.403 Loss = 1.9520857\n",
            "52 Training accuracy = 0.377 Loss = 1.944075\n",
            "53 Training accuracy = 0.39 Loss = 1.9236082\n",
            "54 Training accuracy = 0.396 Loss = 1.897472\n",
            "55 Training accuracy = 0.384 Loss = 1.9014161\n",
            "56 Training accuracy = 0.369 Loss = 1.8773261\n",
            "57 Training accuracy = 0.39 Loss = 1.8526752\n",
            "58 Training accuracy = 0.385 Loss = 1.8528733\n",
            "59 Training accuracy = 0.399 Loss = 1.8118265\n",
            "60 Training accuracy = 0.383 Loss = 1.8199424\n",
            "61 Training accuracy = 0.397 Loss = 1.809807\n",
            "62 Training accuracy = 0.408 Loss = 1.7779826\n",
            "63 Training accuracy = 0.408 Loss = 1.7623521\n",
            "64 Training accuracy = 0.407 Loss = 1.7443796\n",
            "65 Training accuracy = 0.429 Loss = 1.7406154\n",
            "66 Training accuracy = 0.44 Loss = 1.705626\n",
            "67 Training accuracy = 0.433 Loss = 1.6901333\n",
            "68 Training accuracy = 0.465 Loss = 1.6916486\n",
            "69 Training accuracy = 0.487 Loss = 1.6643555\n",
            "70 Training accuracy = 0.501 Loss = 1.6367956\n",
            "71 Training accuracy = 0.486 Loss = 1.6474822\n",
            "72 Training accuracy = 0.517 Loss = 1.6433977\n",
            "73 Training accuracy = 0.535 Loss = 1.6033092\n",
            "74 Training accuracy = 0.538 Loss = 1.5897487\n",
            "75 Training accuracy = 0.514 Loss = 1.5991069\n",
            "76 Training accuracy = 0.539 Loss = 1.5707437\n",
            "77 Training accuracy = 0.562 Loss = 1.5281342\n",
            "78 Training accuracy = 0.567 Loss = 1.5423331\n",
            "79 Training accuracy = 0.57 Loss = 1.5429457\n",
            "80 Training accuracy = 0.592 Loss = 1.5067538\n",
            "81 Training accuracy = 0.582 Loss = 1.4962808\n",
            "82 Training accuracy = 0.592 Loss = 1.475507\n",
            "83 Training accuracy = 0.602 Loss = 1.4460517\n",
            "84 Training accuracy = 0.588 Loss = 1.4469374\n",
            "85 Training accuracy = 0.565 Loss = 1.4777294\n",
            "86 Training accuracy = 0.612 Loss = 1.4324852\n",
            "87 Training accuracy = 0.606 Loss = 1.4387077\n",
            "88 Training accuracy = 0.615 Loss = 1.4097004\n",
            "89 Training accuracy = 0.602 Loss = 1.4017195\n",
            "90 Training accuracy = 0.64 Loss = 1.376891\n",
            "91 Training accuracy = 0.62 Loss = 1.3638862\n",
            "92 Training accuracy = 0.601 Loss = 1.3922937\n",
            "93 Training accuracy = 0.629 Loss = 1.3290863\n",
            "94 Training accuracy = 0.63 Loss = 1.3379006\n",
            "95 Training accuracy = 0.642 Loss = 1.3188527\n",
            "96 Training accuracy = 0.603 Loss = 1.3209494\n",
            "97 Training accuracy = 0.65 Loss = 1.3096942\n",
            "98 Training accuracy = 0.629 Loss = 1.2999053\n",
            "99 Training accuracy = 0.622 Loss = 1.2941859\n",
            "100 Training accuracy = 0.635 Loss = 1.2885828\n",
            "101 Training accuracy = 0.645 Loss = 1.2822405\n",
            "102 Training accuracy = 0.65 Loss = 1.2663089\n",
            "103 Training accuracy = 0.653 Loss = 1.2594748\n",
            "104 Training accuracy = 0.647 Loss = 1.2647563\n",
            "105 Training accuracy = 0.691 Loss = 1.1736842\n",
            "106 Training accuracy = 0.649 Loss = 1.2297347\n",
            "107 Training accuracy = 0.659 Loss = 1.1820686\n",
            "108 Training accuracy = 0.662 Loss = 1.1940175\n",
            "109 Training accuracy = 0.653 Loss = 1.2094611\n",
            "110 Training accuracy = 0.686 Loss = 1.159643\n",
            "111 Training accuracy = 0.673 Loss = 1.1514101\n",
            "112 Training accuracy = 0.66 Loss = 1.1560088\n",
            "113 Training accuracy = 0.655 Loss = 1.1592642\n",
            "114 Training accuracy = 0.65 Loss = 1.1355205\n",
            "115 Training accuracy = 0.68 Loss = 1.1065352\n",
            "116 Training accuracy = 0.675 Loss = 1.1138386\n",
            "117 Training accuracy = 0.665 Loss = 1.0991769\n",
            "118 Training accuracy = 0.684 Loss = 1.076594\n",
            "119 Training accuracy = 0.676 Loss = 1.1102295\n",
            "120 Training accuracy = 0.7 Loss = 1.0896976\n",
            "121 Training accuracy = 0.703 Loss = 1.0675365\n",
            "122 Training accuracy = 0.7 Loss = 1.0757712\n",
            "123 Training accuracy = 0.709 Loss = 1.0651975\n",
            "124 Training accuracy = 0.673 Loss = 1.0813671\n",
            "125 Training accuracy = 0.71 Loss = 1.0537865\n",
            "126 Training accuracy = 0.71 Loss = 1.0318686\n",
            "127 Training accuracy = 0.749 Loss = 0.99237\n",
            "128 Training accuracy = 0.729 Loss = 1.0028977\n",
            "129 Training accuracy = 0.711 Loss = 1.0251096\n",
            "130 Training accuracy = 0.755 Loss = 0.9872101\n",
            "131 Training accuracy = 0.765 Loss = 1.0008446\n",
            "132 Training accuracy = 0.751 Loss = 0.9904752\n",
            "133 Training accuracy = 0.764 Loss = 0.97761333\n",
            "134 Training accuracy = 0.761 Loss = 0.9849704\n",
            "135 Training accuracy = 0.748 Loss = 0.9853065\n",
            "136 Training accuracy = 0.768 Loss = 0.95075756\n",
            "137 Training accuracy = 0.767 Loss = 0.9596221\n",
            "138 Training accuracy = 0.763 Loss = 0.9410431\n",
            "139 Training accuracy = 0.774 Loss = 0.9353039\n",
            "140 Training accuracy = 0.757 Loss = 0.9169491\n",
            "141 Training accuracy = 0.778 Loss = 0.9009896\n",
            "142 Training accuracy = 0.766 Loss = 0.89539874\n",
            "143 Training accuracy = 0.768 Loss = 0.9142806\n",
            "144 Training accuracy = 0.767 Loss = 0.89858603\n",
            "145 Training accuracy = 0.763 Loss = 0.9071687\n",
            "146 Training accuracy = 0.76 Loss = 0.90636194\n",
            "147 Training accuracy = 0.78 Loss = 0.87313706\n",
            "148 Training accuracy = 0.747 Loss = 0.9043813\n",
            "149 Training accuracy = 0.765 Loss = 0.88412887\n",
            "150 Training accuracy = 0.794 Loss = 0.848299\n",
            "151 Training accuracy = 0.765 Loss = 0.8670906\n",
            "152 Training accuracy = 0.782 Loss = 0.8714968\n",
            "153 Training accuracy = 0.779 Loss = 0.8525947\n",
            "154 Training accuracy = 0.762 Loss = 0.84728014\n",
            "155 Training accuracy = 0.789 Loss = 0.8499651\n",
            "156 Training accuracy = 0.776 Loss = 0.88687426\n",
            "157 Training accuracy = 0.794 Loss = 0.80895996\n",
            "158 Training accuracy = 0.764 Loss = 0.8545462\n",
            "159 Training accuracy = 0.802 Loss = 0.8056175\n",
            "160 Training accuracy = 0.814 Loss = 0.8450017\n",
            "161 Training accuracy = 0.791 Loss = 0.82275814\n",
            "162 Training accuracy = 0.795 Loss = 0.8186801\n",
            "163 Training accuracy = 0.807 Loss = 0.80308586\n",
            "164 Training accuracy = 0.8 Loss = 0.80156165\n",
            "165 Training accuracy = 0.805 Loss = 0.78608596\n",
            "166 Training accuracy = 0.82 Loss = 0.79924405\n",
            "167 Training accuracy = 0.815 Loss = 0.7613795\n",
            "168 Training accuracy = 0.811 Loss = 0.7970306\n",
            "169 Training accuracy = 0.803 Loss = 0.7821583\n",
            "170 Training accuracy = 0.822 Loss = 0.7486388\n",
            "171 Training accuracy = 0.815 Loss = 0.7679957\n",
            "172 Training accuracy = 0.824 Loss = 0.72974056\n",
            "173 Training accuracy = 0.837 Loss = 0.7230807\n",
            "174 Training accuracy = 0.816 Loss = 0.73618\n",
            "175 Training accuracy = 0.826 Loss = 0.74666065\n",
            "176 Training accuracy = 0.832 Loss = 0.73000747\n",
            "177 Training accuracy = 0.82 Loss = 0.74773926\n",
            "178 Training accuracy = 0.83 Loss = 0.71977746\n",
            "179 Training accuracy = 0.839 Loss = 0.7165535\n",
            "180 Training accuracy = 0.827 Loss = 0.69954073\n",
            "181 Training accuracy = 0.775 Loss = 0.7226962\n",
            "182 Training accuracy = 0.801 Loss = 0.69357646\n",
            "183 Training accuracy = 0.809 Loss = 0.7183757\n",
            "184 Training accuracy = 0.79 Loss = 0.7447721\n",
            "185 Training accuracy = 0.818 Loss = 0.6901553\n",
            "186 Training accuracy = 0.835 Loss = 0.6931604\n",
            "187 Training accuracy = 0.822 Loss = 0.7167076\n",
            "188 Training accuracy = 0.833 Loss = 0.68903166\n",
            "189 Training accuracy = 0.845 Loss = 0.67307425\n",
            "190 Training accuracy = 0.835 Loss = 0.6841438\n",
            "191 Training accuracy = 0.815 Loss = 0.68768287\n",
            "192 Training accuracy = 0.833 Loss = 0.65122354\n",
            "193 Training accuracy = 0.836 Loss = 0.68020827\n",
            "194 Training accuracy = 0.834 Loss = 0.64680624\n",
            "195 Training accuracy = 0.842 Loss = 0.663632\n",
            "196 Training accuracy = 0.82 Loss = 0.70574194\n",
            "197 Training accuracy = 0.837 Loss = 0.6434626\n",
            "198 Training accuracy = 0.837 Loss = 0.63866246\n",
            "199 Training accuracy = 0.828 Loss = 0.6573398\n",
            "200 Training accuracy = 0.845 Loss = 0.6338719\n",
            "201 Training accuracy = 0.836 Loss = 0.6497812\n",
            "202 Training accuracy = 0.846 Loss = 0.6425034\n",
            "203 Training accuracy = 0.834 Loss = 0.6568861\n",
            "204 Training accuracy = 0.859 Loss = 0.60974807\n",
            "205 Training accuracy = 0.865 Loss = 0.61269885\n",
            "206 Training accuracy = 0.83 Loss = 0.6115462\n",
            "207 Training accuracy = 0.853 Loss = 0.6428128\n",
            "208 Training accuracy = 0.848 Loss = 0.62370586\n",
            "209 Training accuracy = 0.86 Loss = 0.6129684\n",
            "210 Training accuracy = 0.834 Loss = 0.6261774\n",
            "211 Training accuracy = 0.828 Loss = 0.6053665\n",
            "212 Training accuracy = 0.821 Loss = 0.63357085\n",
            "213 Training accuracy = 0.815 Loss = 0.63731825\n",
            "214 Training accuracy = 0.833 Loss = 0.58386767\n",
            "215 Training accuracy = 0.827 Loss = 0.58527774\n",
            "216 Training accuracy = 0.805 Loss = 0.5886697\n",
            "217 Training accuracy = 0.834 Loss = 0.5887242\n",
            "218 Training accuracy = 0.833 Loss = 0.58304185\n",
            "219 Training accuracy = 0.829 Loss = 0.574173\n",
            "220 Training accuracy = 0.818 Loss = 0.5904773\n",
            "221 Training accuracy = 0.824 Loss = 0.59981406\n",
            "222 Training accuracy = 0.834 Loss = 0.5819958\n",
            "223 Training accuracy = 0.857 Loss = 0.5441553\n",
            "224 Training accuracy = 0.853 Loss = 0.5653628\n",
            "225 Training accuracy = 0.864 Loss = 0.5718513\n",
            "226 Training accuracy = 0.877 Loss = 0.5405655\n",
            "227 Training accuracy = 0.878 Loss = 0.5296733\n",
            "228 Training accuracy = 0.869 Loss = 0.54731023\n",
            "229 Training accuracy = 0.882 Loss = 0.5294271\n",
            "230 Training accuracy = 0.897 Loss = 0.5064048\n",
            "231 Training accuracy = 0.883 Loss = 0.5414744\n",
            "232 Training accuracy = 0.848 Loss = 0.5255513\n",
            "233 Training accuracy = 0.835 Loss = 0.5533625\n",
            "234 Training accuracy = 0.843 Loss = 0.53277236\n",
            "235 Training accuracy = 0.848 Loss = 0.5382527\n",
            "236 Training accuracy = 0.863 Loss = 0.4985871\n",
            "237 Training accuracy = 0.842 Loss = 0.5185169\n",
            "238 Training accuracy = 0.843 Loss = 0.52654356\n",
            "239 Training accuracy = 0.826 Loss = 0.5386135\n",
            "240 Training accuracy = 0.846 Loss = 0.5225842\n",
            "241 Training accuracy = 0.829 Loss = 0.5509166\n",
            "242 Training accuracy = 0.836 Loss = 0.53388476\n",
            "243 Training accuracy = 0.859 Loss = 0.49752924\n",
            "244 Training accuracy = 0.847 Loss = 0.5200905\n",
            "245 Training accuracy = 0.847 Loss = 0.5356193\n",
            "246 Training accuracy = 0.885 Loss = 0.5344216\n",
            "247 Training accuracy = 0.899 Loss = 0.46549684\n",
            "248 Training accuracy = 0.842 Loss = 0.5189111\n",
            "249 Training accuracy = 0.852 Loss = 0.49596247\n",
            "250 Training accuracy = 0.857 Loss = 0.5125843\n",
            "251 Training accuracy = 0.857 Loss = 0.4863131\n",
            "252 Training accuracy = 0.864 Loss = 0.47865784\n",
            "253 Training accuracy = 0.871 Loss = 0.47918645\n",
            "254 Training accuracy = 0.849 Loss = 0.48395965\n",
            "255 Training accuracy = 0.854 Loss = 0.47460935\n",
            "256 Training accuracy = 0.86 Loss = 0.4784234\n",
            "257 Training accuracy = 0.846 Loss = 0.4791081\n",
            "258 Training accuracy = 0.861 Loss = 0.4427198\n",
            "259 Training accuracy = 0.861 Loss = 0.48469985\n",
            "260 Training accuracy = 0.843 Loss = 0.50429237\n",
            "261 Training accuracy = 0.881 Loss = 0.4677119\n",
            "262 Training accuracy = 0.891 Loss = 0.45245868\n",
            "263 Training accuracy = 0.887 Loss = 0.48262456\n",
            "264 Training accuracy = 0.894 Loss = 0.45093462\n",
            "265 Training accuracy = 0.884 Loss = 0.472423\n",
            "266 Training accuracy = 0.896 Loss = 0.4853988\n",
            "267 Training accuracy = 0.913 Loss = 0.45454022\n",
            "268 Training accuracy = 0.89 Loss = 0.456105\n",
            "269 Training accuracy = 0.888 Loss = 0.4607662\n",
            "270 Training accuracy = 0.898 Loss = 0.476601\n",
            "271 Training accuracy = 0.891 Loss = 0.4782037\n",
            "272 Training accuracy = 0.89 Loss = 0.46728927\n",
            "273 Training accuracy = 0.899 Loss = 0.44634956\n",
            "274 Training accuracy = 0.901 Loss = 0.46275103\n",
            "275 Training accuracy = 0.909 Loss = 0.44992194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyDs1KJX9j28",
        "colab_type": "code",
        "outputId": "04e92546-2d02-441d-aa09-3c9c722ae740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Model Evaluation\n",
        "test_data = {X:mnist.test.images,y:mnist.test.labels}\n",
        "print(\"Testing Accuracy = \", sess.run(accuracy, feed_dict = test_data))\n",
        "\n",
        "#lmao I got the worse accuracy\n",
        "#but it is random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy =  0.9001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZpl0P6e9j2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}